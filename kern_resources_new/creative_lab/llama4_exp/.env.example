# Llama 4 Integration Configuration

# Ollama API configuration
# Local Ollama instance
# OLLAMA_API_BASE=http://localhost:11434

# Remote Ollama instance on Render
OLLAMA_API_BASE=https://ollama-llama4.onrender.com

# Ollama request configuration
OLLAMA_TIMEOUT=120
OLLAMA_REMOTE=true

# Model configuration
SCOUT_MODEL_NAME=llama4-scout-instruct
E_MODEL_NAME=llama4-e-17b

# CrewAI configuration
CREWAI_VERBOSE=True

# Training configuration (for Track 2)
# TRAINING_DATA_PATH=./data/training
# EVALUATION_DATA_PATH=./data/evaluation
# OUTPUT_DIR=./models/fine_tuned
# LEARNING_RATE=2e-4
# BATCH_SIZE=4
# NUM_EPOCHS=3
